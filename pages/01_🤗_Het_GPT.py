import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
from huggingface_hub import InferenceClient  # Hugging Face API í´ë¼ì´ì–¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
from dotenv import load_dotenv  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os  # ìš´ì˜ ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = os.getenv("HUGGINGFACE_API_KEY")  # API í‚¤ ê°€ì ¸ì˜¤ê¸°

# Hugging Face API ì„¤ì •
client = InferenceClient(provider="hf-inference", api_key=api_key)  # Hugging Face API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

# Streamlit UI ì„¤ì •
st.set_page_config(page_title="í—·GPT", page_icon="ğŸ’¬", layout="wide")  # í˜ì´ì§€ ì œëª©, ì•„ì´ì½˜ ë° ë ˆì´ì•„ì›ƒ ì„¤ì •

# í˜„ì¬ í˜ì´ì§€ì— ëŒ€í•œ ê³ ìœ í•œ í‚¤ ìƒì„± (í˜ì´ì§€ë³„ ëŒ€í™” ê¸°ë¡ ìœ ì§€)
current_page = "ai_het_assistant"  # í˜„ì¬ í˜ì´ì§€ì˜ ê³ ìœ í•œ ì‹ë³„ì
page_key = f"chat_history_{current_page}"

# í˜ì´ì§€ë³„ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if page_key not in st.session_state:
    st.session_state[page_key] = []
# ì‚¬ì´ë“œë°” ì¶”ê°€
with st.sidebar:
    st.header("ğŸ“Œ ì„¤ì •")  # ì‚¬ì´ë“œë°” í—¤ë”
    clear_chat = st.button("ğŸ’¬ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”")  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
    
    if clear_chat:
        st.session_state[page_key] = []  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
        st.success("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")  # ì„±ê³µ ë©”ì‹œì§€ ì¶œë ¥

# ë©”ì¸ ì œëª© ë° ì„¤ëª…
st.title("ğŸ’¬ ë˜‘ë˜‘í•œ AI í—·GPT")  # ë©”ì¸ í˜ì´ì§€ ì œëª©
st.write("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ í—·GPTê°€ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")  # í˜ì´ì§€ ì„¤ëª…

# ëŒ€í™” ê¸°ë¡ ì €ì¥
if "chat_history" not in st.session_state:
    st.session_state[page_key] = []  # ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”

# AI ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜
def get_response():
    # ì˜¬ë°”ë¥¸ ì…ë ¥ ê°’ ê°€ì ¸ì˜¤ê¸° (ì…ë ¥ í•„ë“œëŠ” "chat_input"ì— ì €ì¥ë©ë‹ˆë‹¤)
    user_input = st.session_state.chat_input  
    if user_input:
        # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ì„ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì˜¤ë˜ëœ ìˆœì„œëŒ€ë¡œ)
        conversation_messages = []
        # ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì€ ìµœì‹  ë©”ì‹œì§€ê°€ ì•ì— ìˆìœ¼ë¯€ë¡œ, ì—­ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
        for role, message in reversed(st.session_state[page_key]):
            if role.startswith("ğŸ‘¤"):  # ì‚¬ìš©ì ë©”ì‹œì§€ì¸ ê²½ìš°
                conversation_messages.append({"role": "user", "content": message})
            elif role.startswith("ğŸ¤–"):  # í—·GPT(assistant) ë©”ì‹œì§€ì¸ ê²½ìš°
                conversation_messages.append({"role": "assistant", "content": message})
        # í˜„ì¬ ì‚¬ìš©ìì˜ ì…ë ¥ë„ ì¶”ê°€í•©ë‹ˆë‹¤.
        conversation_messages.append({"role": "user", "content": user_input})
        
        with st.spinner("í—·GPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = client.chat.completions.create(
                model="google/gemma-2-9b-it",
                messages=conversation_messages,  # ëŒ€í™” ì´ë ¥ì„ í¬í•¨í•œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                max_tokens=1024,
            ).choices[0].message.content
            
            # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ (ìµœì‹  ë©”ì‹œì§€ê°€ ìœ„ì— í‘œì‹œë˜ë„ë¡)
            st.session_state[page_key].insert(0, ("ğŸ¤– í—·GPT:", response))
            st.session_state[page_key].insert(0, ("ğŸ‘¤ ì‚¬ìš©ì:", user_input))
            st.session_state.pop("chat_input", None)
            
# ëŒ€í™” ì¶œë ¥ (ìµœì‹  ë©”ì‹œì§€ê°€ ìœ„ë¡œ)
st.markdown("### ëŒ€í™” ê¸°ë¡")  # ëŒ€í™” ê¸°ë¡ ì„¹ì…˜ ì œëª© ì¶œë ¥
for role, message in reversed(st.session_state[page_key]):  # ëŒ€í™” ê¸°ë¡ì„ ì—­ìˆœìœ¼ë¡œ ì¶œë ¥
    st.markdown(f"**{role}** {message}")

# ì…ë ¥ í•„ë“œ
st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="chat_input", on_submit=get_response)  # ì‚¬ìš©ì ì…ë ¥ í•„ë“œ ì„¤ì • ë° ì‘ë‹µ í•¨ìˆ˜ ì—°ê²°
