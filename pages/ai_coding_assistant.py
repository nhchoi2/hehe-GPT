import streamlit as st  # ì›¹ UI ìƒì„±ì„ ìœ„í•œ Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from huggingface_hub import InferenceClient  # Hugging Face Inference API ì‚¬ìš©ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ì„í¬íŠ¸
import os  # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ ì‚¬ìš© (í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë“±)
from dotenv import load_dotenv  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ------------------------------------------------------------------------
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ------------------------------------------------------------------------
load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
api_key = os.getenv("HUGGINGFACE_API_KEY")  # HUGGINGFACE_API_KEY í™˜ê²½ ë³€ìˆ˜ ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

# ------------------------------------------------------------------------
# Streamlit í˜ì´ì§€ ì„¤ì •
# ------------------------------------------------------------------------
st.set_page_config(
    page_title="ì½”ë“œí—·GPT",  # ë¸Œë¼ìš°ì € íƒ­ì— í‘œì‹œë  í˜ì´ì§€ ì œëª©
    page_icon="ğŸ¤–",              # í˜ì´ì§€ ì•„ì´ì½˜ (ì´ëª¨ì§€ ì‚¬ìš©)
    layout="wide"               # í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ ì™€ì´ë“œ ëª¨ë“œë¡œ ì„¤ì •
)

# ------------------------------------------------------------------------
# ì‚¬ì´ë“œë°”: ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
# ------------------------------------------------------------------------
# ì‚¬ìš©ìê°€ ì‚¬ì´ë“œë°”ì— ìˆëŠ” "ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”" ë²„íŠ¼ì„ ëˆ„ë¥´ë©´, ëŒ€í™” ê¸°ë¡ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
if st.sidebar.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
    st.session_state.chat_history = []

# ------------------------------------------------------------------------
# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ------------------------------------------------------------------------
# st.session_stateë¥¼ ì‚¬ìš©í•´ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•©ë‹ˆë‹¤.
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ------------------------------------------------------------------------
# í˜ì´ì§€ ì œëª© ë° ì„¤ëª… í‘œì‹œ
# ------------------------------------------------------------------------
st.title("ğŸ¤– ì½”ë“œí—·GPT")
st.write("ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´ í—·GPTê°€ ê°œì„ ì , ë””ë²„ê¹… ë°©ë²• ë“±ì„ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤!")

# ------------------------------------------------------------------------
# Hugging Face InferenceClient ì´ˆê¸°í™”
# ------------------------------------------------------------------------
# API í‚¤ë¥¼ ì‚¬ìš©í•´ Inference API í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
client = InferenceClient(provider="hf-inference", api_key=api_key)

# ------------------------------------------------------------------------
# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
# ------------------------------------------------------------------------
# ì´ë¯¸ ì €ì¥ëœ ëŒ€í™” ê¸°ë¡(ì„¸ì…˜ ìƒíƒœ)ì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
for chat in st.session_state.chat_history:
    if chat["role"] == "user":
        st.chat_message("user").write(chat["content"])  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    else:
        st.chat_message("assistant").write(chat["content"])  # AI(ì–´ì‹œìŠ¤í„´íŠ¸) ë©”ì‹œì§€ ì¶œë ¥

# ------------------------------------------------------------------------
# ì‚¬ìš©ìë¡œë¶€í„° ì½”ë“œ ì…ë ¥ ë°›ê¸° (ëŒ€í™”í˜• ì…ë ¥ì°½)
# ------------------------------------------------------------------------
# st.chat_input()ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì½”ë“œë¥¼ ì…ë ¥ ë°›ìŠµë‹ˆë‹¤.
user_input = st.chat_input("ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")

# ------------------------------------------------------------------------
# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° AI ì‘ë‹µ ìƒì„±
# ------------------------------------------------------------------------
if user_input:
    # ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    # AI ì‘ë‹µ ìƒì„± ìš”ì²­: ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ë¬¸ë§¥ ê¸°ë°˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    with st.spinner("í—·GPTê°€ ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        response = client.chat.completions.create(
            model="Qwen/Qwen2.5-Coder-32B-Instruct",  # ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ì— íŠ¹í™”ëœ ëª¨ë¸ ì‚¬ìš©
            messages=st.session_state.chat_history,   # ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡ ì „ë‹¬
            max_tokens=1024,                           # ìƒì„±ë  ì‘ë‹µì˜ ìµœëŒ€ í† í° ìˆ˜ ì„¤ì •
        )
        # ëª¨ë¸ ì‘ë‹µì—ì„œ ì²« ë²ˆì§¸ ì„ íƒì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        assistant_message = response.choices[0].message.content

    # ìƒì„±ëœ AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤.
    st.session_state.chat_history.append({"role": "assistant", "content": assistant_message})
    st.chat_message("assistant").write(assistant_message)
