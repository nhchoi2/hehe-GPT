import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
from huggingface_hub import InferenceClient  # Hugging Face API í´ë¼ì´ì–¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
from dotenv import load_dotenv  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os  # ìš´ì˜ ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
api_key = os.getenv("HUGGINGFACE_API_KEY")  # API í‚¤ ê°€ì ¸ì˜¤ê¸°

# Hugging Face API ì„¤ì •
client = InferenceClient(provider="hf-inference", api_key=api_key)  # Hugging Face API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”

# Streamlit UI ì„¤ì •
st.set_page_config(page_title="í—·GPT", page_icon="ğŸ’¬", layout="wide")  # í˜ì´ì§€ ì œëª©, ì•„ì´ì½˜ ë° ë ˆì´ì•„ì›ƒ ì„¤ì •

# ì‚¬ì´ë“œë°” ì¶”ê°€
with st.sidebar:
    st.header("ğŸ“Œ ì„¤ì •")  # ì‚¬ì´ë“œë°” í—¤ë”
    clear_chat = st.button("ğŸ’¬ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”")  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
    
    if clear_chat:
        st.session_state.chat_history = []  # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
        st.success("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")  # ì„±ê³µ ë©”ì‹œì§€ ì¶œë ¥

# ë©”ì¸ ì œëª© ë° ì„¤ëª…
st.title("ğŸ’¬ ë˜‘ë˜‘í•œ AI í—·GPT")  # ë©”ì¸ í˜ì´ì§€ ì œëª©
st.write("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ í—·GPTê°€ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")  # í˜ì´ì§€ ì„¤ëª…

# ëŒ€í™” ê¸°ë¡ ì €ì¥
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # ì„¸ì…˜ ìƒíƒœì— ëŒ€í™” ê¸°ë¡ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”

# AI ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜
def get_response():
    user_input = st.session_state.chat_input  # ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    if user_input:
        with st.spinner("í—·GPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):  # AI ì‘ë‹µ ìƒì„± ì¤‘ ìŠ¤í”¼ë„ˆ í‘œì‹œ
            response = client.chat.completions.create(
                model="google/gemma-2-9b-it",  # ì‚¬ìš© ëª¨ë¸ ì§€ì •
                messages=[{"role": "user", "content": user_input}],  # ì‚¬ìš©ì ë©”ì‹œì§€ ì „ë‹¬
                max_tokens=1024,  # ìµœëŒ€ í† í° ì„¤ì •
            ).choices[0].message.content  # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ì¶œ
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            st.session_state.chat_history.insert(0, ("ğŸ‘¤ ì‚¬ìš©ì:", user_input))  # ì‚¬ìš©ì ì…ë ¥ ì €ì¥
            st.session_state.chat_history.insert(0, ("ğŸ¤– í—·GPT:", response))  # AI ì‘ë‹µ ì €ì¥
            st.session_state.pop("chat_input", None)  # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”

# ëŒ€í™” ì¶œë ¥ (ìµœì‹  ë©”ì‹œì§€ê°€ ìœ„ë¡œ)
st.markdown("### ëŒ€í™” ê¸°ë¡")  # ëŒ€í™” ê¸°ë¡ ì„¹ì…˜ ì œëª© ì¶œë ¥
for role, message in reversed(st.session_state.chat_history):  # ëŒ€í™” ê¸°ë¡ì„ ì—­ìˆœìœ¼ë¡œ ì¶œë ¥
    st.markdown(f"**{role}** {message}")

# ì…ë ¥ í•„ë“œ
st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="chat_input", on_submit=get_response)  # ì‚¬ìš©ì ì…ë ¥ í•„ë“œ ì„¤ì • ë° ì‘ë‹µ í•¨ìˆ˜ ì—°ê²°
