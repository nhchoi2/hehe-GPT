import streamlit as st
from huggingface_hub import InferenceClient
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("HUGGINGFACE_API_KEY")

# Hugging Face API ì„¤ì •
client = InferenceClient(
    provider="hf-inference",
    api_key=api_key
)

# Streamlit UI ì„¤ì •
st.set_page_config(page_title="AI ê³ ê° ìƒë‹´ ì±—ë´‡", page_icon="ğŸ’¬", layout="wide")

st.markdown(
    """
    <style>
        .stTextInput > div > div > input {
            font-size: 16px;
            padding: 10px;
            border-radius: 10px;
        }
        .stButton > button {
            background-color: #007BFF;
            color: white;
            font-size: 16px;
            border-radius: 10px;
            padding: 10px 20px;
        }
        .stMarkdown {
            font-size: 18px;
            line-height: 1.6;
        }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ’¬ ë§ì¶¤í˜• ë‚˜ë§Œì˜ AI í—¤í—¤^^ GPT")
st.write("ê³ ê°ë‹˜ì˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")

# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ê³µê°„ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ëŒ€í™” ì¶œë ¥ (ìµœì‹  ë©”ì‹œì§€ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì—­ìˆœ ì •ë ¬)
st.markdown("### ëŒ€í™” ê¸°ë¡")
chat_container = st.container()
with chat_container:
    for role, message in reversed(st.session_state.chat_history):  # ìµœì‹  ë©”ì‹œì§€ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ë³€ê²½
        st.markdown(f"**{role}** {message}")

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
col1, col2 = st.columns([4, 1])

def get_response():
    user_input = st.session_state.user_input
    if user_input:
        with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            messages = [{"role": "user", "content": user_input}]
            completion = client.chat.completions.create(
                model="google/gemma-2-9b-it", 
                messages=messages, 
                max_tokens=1024,
            )
            response = completion.choices[0].message.content
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            st.session_state.chat_history.insert(0, ("ğŸ‘¤ ì‚¬ìš©ì:", user_input))
            st.session_state.chat_history.insert(0, ("ğŸ¤– í—¤í—¤^^ GPT:", response))
            
            
            # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
            st.session_state.user_input = ""

# ì…ë ¥ í•„ë“œ & ë²„íŠ¼ ë°°ì¹˜
with col1:
    st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_input", on_change=get_response, placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")


st.markdown("---")
st.write("ì´ ì±—ë´‡ì€ ê³ ê° ìƒë‹´ ë° AI ì§€ì›ì„ ì œê³µí•©ë‹ˆë‹¤. ğŸš€")
